---
layout: post
title:  "lab3"
category: "canhaplabs"
---

# Lab 3: Communicate something with Haply


*Note: I worked on this lab with Sri!*

## Finding the words

Sri and I decided that the most efficient way to tackle this lab would be to start with a quick brainstorming session. We created a virtual bulletin board and started thinking up juicy [ten dollar words](https://en.wiktionary.org/wiki/ten-dollar_word#English). After thinking of a few, we grouped them into categories of related words.

{% include figure image_path="/assets/lab3/brainstorming.png" alt="brainstorming words." caption="_The words and word categories we came up with._" %}

We both thought the "toxic" and "sense of direction (negative)" categories felt the most promising haptically, so we decided to dive into some of those words to see what we came up with.

We ended up focusing on "misleading," "arrogant," "lethargic," and "spiky," as they were the words that we immediately had ideas for.

## Playing with haptics

### "misleading"

{% include figure image_path="/assets/lab3/mislead.gif" alt="misleading." caption="_What we thought 'misleading' feels like._" %}

For "misleading," we thought it would feel jarring to have the floor disappear out from under you and reappear again. Originally, we made the entire floor effectively disappear by creating one `FBox` and using the `setSensor()` method, but because the method does not work instantaneously, we switched our approach to creating a sort of "trapdoor." If the end effector is moving to the right, the fake floor is completely solid, but if the end effector moves to the left, part of the floor "disappears" and allows the end effector through.

```java
    if (mislead) {
      if (checkPassThroughWall(positionArr)) {
        wall[2].setSensor(true);
      } 
      else {
        wall[2].setSensor(false);
      }
    }
```
*The core of the "mislead" haptic metaphor. `checkPassThroughWall()` simply checks to see if the end effector has moved left or right.*

### "arrogant"

{% include figure image_path="/assets/lab3/arrogant.gif" alt="arrogant." caption="_What we thought 'arrogant' feels like._" %}

When we discussed "arrogant," we conceptualized it as "someone taking up space" so we thought we'd translate that into a circle that grows depending on how fast the end effector moves. We wanted to add a bit more texture, so we added an `FBlob` around the circle that the end effector is able to pass through. We also made the circle and the blob shrink if the end effector is still or moves slowly enough for a short period, as if it is tiptoeing around the arrogant object pair.

{% include figure image_path="/assets/lab3/arrogant.png" alt="arrogant beginnings." caption="_'Arrogant' begins looking like a weird egg._" %}

```java
    if (inflate) {
      setBlobSize(arrogance, blobSize);
      circle.setSize(circleSize);
      delay(50);
      speed = Math.abs(s.h_avatar.getVelocityX());
      if (speed >10 && circleSize<20) {
        circleSize += deltaTime*0.01 + speed*0.005;
        blobSize += deltaTime*0.01 + speed*0.01;
        growDelta = 0f;
      } 
      else {
        if (growDelta > 50 && circleSize > 1) {
          circleSize -= deltaTime*0.0005;
          blobSize -= deltaTime*0.0005;
        }
        growDelta += deltaTime;
      }
    }

```
*The core of the "arrogant" haptic metaphor. `deltaTime` is the amount of milliseconds that have passed since the last `draw()` loop.*


### "lethargic"

{% include figure image_path="/assets/lab3/lethargic.gif" alt="lethargic." caption="_What we thought 'lethargic' feels like._" %}

When we discussed "lethargic," we were both in agreement that it felt like moving takes a lot of effort. That to us translated nicely into high damping, so for the haptic metaphor we simply created an area with high damping. Simple, yet highly effective!

```java
void beginLeth() {

  createRegion();
  s.h_avatar.setDamping(800);
}

void clearLeth() {
  leth = false;
  world.remove(region);
  s.h_avatar.setDamping(40);
}
```
*The core to our 'lethargic' code.*

### "spiky"

{% include figure image_path="/assets/lab3/spiky.gif" alt="spiky." caption="_'Spiky' ended up a struggle for us._" %}

Our vision for "spiky" was to populate the canvas with circles that would "pop" when the end effector touched them. However, we could not figure out a good way to get the popping sensation to feel right! When we tried using `setSensor()`, the circles would unceremoniously "disappear," but they wouldn't feel like popping. We also kept getting `concurrentModificationException`s. We eventually decided that we were having enough problems with this haptic metaphor and so scrapped it.

## The code

The full code base can be found [here](https://github.com/linneakirby/canhaplabs/tree/main/lab3).

## Guessing the haptic metaphor

We were able to get four people of a variety of backgrounds to test out our haptic metaphors. We set up our code with a `final boolean DEBUG` that toggles the visibility of all the haptic metaphors.

For Testers 1 and 2, we only got their reactions interacting with the invisible objects. For Testers 3 and 4, we first had them guess the haptic metaphor without being able to see the objects, and then revealed the objects to see if they had any additional comments.

### Tester 1 – Student in the class

> lol, i'd say spring for the first one, cause like there's some push and pull, push for the second cause there's this huge force wall in between or something and gluey for the third, cause it feels like im stuck in a honey like substance. or dense or viscous

### Tester 2 – Non-computer-engineer grad student

> uh i don’t know… jittery… narrow… and friction. but i am not a good person to ask

### Tester 3 – Recent high school graduate

Without being able to see the objects:
> shimmering, left, and wobbling

After seeing the objects:

**Misleading**
>trapdoor! is it trapdoor?

**Lethargic**
>oh it’s just a blob! that you can pass through?? oh it’s just harder to pass through


### Tester 4 – Professional software engineer

Without being able to see the objects:
>line. ok fine... pencil?
>
>the first one is house, the second one is cork and the third one is waterfall or something like that

After seeing the objects:

**Misleading**
>oh it’s like a misleading door!

**Arrogant**
>omg it grows! i don’t like it
>
> i knew it was an egg!

## Reflection

Overall, our results were mixed. Each tester had at least one guess that was similar to what we were envisioning, which is somewhat encouraging. However, most of the guesses were not at all close. When the visuals were added in, the comments got closer to our intentions, but it is clear that our attempts at conveying meaning with haptics alone have a ways to go before they can communicate effectively.

I can think of several potential hinderances to the effectiveness of the haptic metaphors:
1. None of the testers were familiar with haptics, even the professional software engineer
2. The Haply felt foreign to most of the testers and frequently froze up due to a tester attempting to force their way through a solid object
3. The Haply is not capable of intricate haptic effects
4. Our knowledge of the capabilities of haptic sensations is still quite basic

I think most of these hinderances (except for number 3) could be solved with more experience with haptic devices and the range of haptic effects that the Haply can perform. In the meantime, I think our rudimentary haptic effects could be much improved with appropriate visuals.
